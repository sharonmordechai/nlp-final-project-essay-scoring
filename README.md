# Cross-Lingual Automated Essay Scoring

## Abstract
Cross-Lingual Automated Essay Scoring: Enhancing Hebrew Language Performance via Transfer Learning of an English Language Model.

This project presents a cross-lingual automated essay scoring system that enhances the performance of Hebrew language essays using transfer learning from an English language model.

The code demonstrates the implementation of transfer learning techniques to fine-tune a pre-trained English language model, creating an accurate and robust scoring model for Hebrew essays. The process involves creating a new language model in English, training it on a large-scale dataset of English essays, and leveraging back translation to convert the dataset into Hebrew. Transfer learning is then applied to adapt the fine-tuned English model to the Hebrew dataset, enabling accurate scoring of Hebrew essays.

The code offers a practical and efficient solution for building cross-lingual automated essay scoring systems, benefiting educators, language learners, and NLP researchers.

## Code
The code for this research project, including the implementation of the models, data processing, evaluation, and prediction, can be found in the following [link](https://colab.research.google.com/drive/1FYni18JW3dbmP5RV_6mdLn1nNaD2HA1b?usp=sharing).
